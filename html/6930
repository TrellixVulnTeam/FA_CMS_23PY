<!DOCTYPE html>
<html lang="ja">
<head>
    <meta http-equiv="Content-Type" content="text/html; charset=UTF-8">
    <meta name="viewport" content="width=device-width,initial-scale=1">

    <meta name="distribution" content="global">
    <meta name="robots" content="follow, all">
    <meta name="language" content="en, sv">

    <title> 睡眠中の脳活動パターンからの夢の内容の解読 : ライフサイエンス 新着論文レビュー</title>

    <link rel="Shortcut Icon" href="./favicons/favicon.ico" type="image/x-icon">
    <link rel="apple-touch-icon" sizes="180x180" href="./favicons/apple-touch-icon.png">
    <link rel="icon" type="image/png" sizes="32x32" href="./favicons/favicon-32x32.png">
    <link rel="icon" type="image/png" sizes="16x16" href="./favicons/favicon-16x16.png">
    <link rel="manifest" href="./favicons/site.webmanifest">
    <link rel="mask-icon" href="./favicons/safari-pinned-tab.svg" color="#2b5797">
    <meta name="msapplication-TileColor" content="#2b5797">
    <meta name="theme-color" content="#ffffff">

    <link rel="alternate" type="application/rss+xml" title="RSS 2.0" href="http://first.lifesciencedb.jp/feed">
    <link rel="alternate" type="text/xml" title="RSS .92" href="http://first.lifesciencedb.jp/feed/rss">
    <link rel="alternate" type="application/atom+xml" title="Atom 0.3" href="http://first.lifesciencedb.jp/feed/atom">
    <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/drawer/3.1.0/css/drawer.min.css">
    <script src="https://cdnjs.cloudflare.com/ajax/libs/jquery/3.1.1/jquery.min.js"></script>
    <script src="https://cdnjs.cloudflare.com/ajax/libs/drawer/3.1.0/js/drawer.min.js"></script>

    <link rel="stylesheet" id="style-maintenance-css" href="./css/style-maintenance.css" type="text/css" media="all">
    <link rel="stylesheet" href="https://use.fontawesome.com/releases/v5.3.1/css/all.css" integrity="sha384-mzrmE5qonljUremFsqc01SB46JvROS7bZs3IO2EmfFsd15uHvIt+Y8vEf7N7fWAU" crossorigin="anonymous">
    <script defer src="https://use.fontawesome.com/releases/v5.0.4/js/all.js"></script>
    <script src="https://cdnjs.cloudflare.com/ajax/libs/iScroll/5.1.3/iscroll.min.js"></script>

    <link rel="stylesheet" id="toc-screen-css" href="./css/screen.min.css" type="text/css" media="all">
    <link rel="https://api.w.org/" href="http://first.lifesciencedb.jp/wp-json/">
    <link rel="EditURI" type="application/rsd+xml" title="RSD" href="http://first.lifesciencedb.jp/xmlrpc.php?rsd">
    <link rel="wlwmanifest" type="application/wlwmanifest+xml"
          href="http://first.lifesciencedb.jp/wp-includes/wlwmanifest.xml">

    <!-- for modal window -->
    <link rel="stylesheet"
          href="https://cdnjs.cloudflare.com/ajax/libs/twitter-bootstrap/4.1.3/css/bootstrap.min.css"
          type="text/css">
    <script src="https://cdnjs.cloudflare.com/ajax/libs/twitter-bootstrap/4.1.3/js/bootstrap.min.js"></script>
    <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/ekko-lightbox/5.3.0/ekko-lightbox.css"
          type="text/css">
    <script src="https://cdnjs.cloudflare.com/ajax/libs/ekko-lightbox/5.3.0/ekko-lightbox.js"></script>


    <link rel="stylesheet" type="text/css" href="./webfonts-css/fa-solid.min.css">
    <link rel="stylesheet" type="text/css" href="./css/style.css">
    <link rel="stylesheet" type="text/css" href="./css/print.css">
</head>

<body class="drawer drawer--left">


<!-- drawer menu -->

<nav class="drawer-nav">
    <div class="inner">
        <ul class="drawer-menu l_sidebarwidgeted">

            <li class="widget widget_search">
                <form id="searchform" class="searchform">
                    <label class="screen-reader-text">検索:</label>
                    <input type="text" ref="search_val" id="search_val" maxlength="20"/>
                    <input type="button" id="searchsubmit" value="検索"/>
                </form>
            </li>

            <drawer-journal></drawer-journal>
            <drawer-category></drawer-category>
            <drawer-date></drawer-date>

            <li class="drawer-nav-menu">
                <ul class="nav-menu">
                    <li class="page_item"><a href="./about">「新着論文レビュー」とは</a></li>
                    <li class="page_item"><a href="./allposts">掲載記事一覧</a></li>
                    <li class="page_item"><a href="./copyright">著作権・クレジット</a></li>
                    <li class="page_item"><a href="./editor">編集人</a></li>
                </ul>
            </li>
        </ul>
    </div>
</nav>


<div id="wrap">
    <div id="nav">
        <div class="nav-inner">
            <button type="button" class="drawer-toggle drawer-hamburger drawer-opener">
                <span class="drawer-opener-pc"><i class="fa fa-search"></i></span>
                <span class="drawer-hamburger-icon"></span>
            </button>
            <ul class="nav-menu" id="nav-menu">
                <li><a href="./index.htm">ホーム</a></li>
                <li class="page_item"><a href="./about">「新着論文レビュー」とは</a></li>
                <li class="page_item"><a href="./allposts">掲載記事一覧</a></li>
                <li class="page_item"><a href="./copyright">著作権・クレジット</a></li>
                <li class="page_item"><a href="./editor">編集人</a></li>
            </ul>
        </div>
    </div>

    <div id="masthead">
        <a href="./index.htm">
            <h1>ライフサイエンス 新着論文レビュー</h1>
            <h3>First author's</h3>
        </a>
    </div>

    <div id="content">

        <div id="contentleft">
            <div class="article">
                <h1><a href="http://first.lifesciencedb.jp/archives/6930" rel="bookmark">睡眠中の脳活動パターンからの夢の内容の解読</a></h1>
                <div class="article_thumb"></div>

                <div class="article_thumb">
                    <strong>堀川友慈・神谷之康</strong><br>（国際電気通信基礎技術研究所（ATR）脳情報研究所神経情報学研究室）<br>email：<a href="mailto:horikawa-t@atr.jp">堀川友慈</a>，<a href="mailto:kmtn@atr.jp">神谷之康</a><br>DOI: <a href="http://dx.doi.org/10.7875/first.author.2013.050">10.7875/first.author.2013.050</a><br><div class="reference"><br><span class="ti">Neural decoding of visual imagery during sleep.</span><br><span class="au">T. Horikawa, M. Tamaki, Y. Miyawaki, Y. Kamitani</span><br><span class="so"><a href="http://www.ncbi.nlm.nih.gov/pubmed/23558170" target="_blank"><em>Science</em>, <strong>340</strong>, 639-642 (2013)</a></span></div><br><br><!--more--><br><br><h2>要 約</h2><br/>　夢は外界からの刺激とは関係なく生じる<a href="#" class="anno 主観的">主観的</a>な現象で，見た本人にしかその内容がわからない，すぐに忘れてしまうなどの理由から，<a href="#" class="anno 客観的">客観的</a>な解析の困難な対象である．この研究では，睡眠中の脳の活動を計測することにより得られた<a href="#" class="anno 脳活動">脳活動</a>パターンを解析することで，夢の内容を解読し客観的に評価する手法を開発することに成功した．実験では，<a href="#" class="anno 機能的">機能的</a><a href="#" class="anno MR">MR</a>Iを用いて睡眠中の脳の活動を計測し，被験者を覚醒させ直前に見ていた夢の内容を言葉で報告させる，という手続きをくり返した．<a href="#" class="anno 実際">実際</a>に画像を見ているときの脳の活動を使い，脳活動パターンから見ている物体を予測する<a href="#" class="anno パターン認識">パターン認識</a>アルゴリズムを構築し，睡眠中の脳の活動を解析することにより，夢の報告に現われた物体を高い精度で予測することに成功した．この結果は，夢を見ているときに<a href="#" class="anno も">も</a>画像を見ているときと共通する脳活動パターンが生じていることを示した．この方法は夢の解読だけでなく，<a href="#" class="anno 自発的">自発的</a>に生じる脳の活動の機能の解明や，幻覚などの<a href="#" class="anno 精神疾患">精神疾患</a>の診断にも貢献することが期待される．<br/><br/><h2>はじめに</h2><br/>　古来，夢はその機能や内容の解釈について多くの人の注目をあつめてきた．しかし，夢の内容は，夢を見た本人にしかわからない，本人自身もすぐに忘れてしまう，などの理由から，客観的な解析の対象とすることが困難であった．従来の睡眠の研究では，夢見体験と睡眠中の脳波や<a href="#" class="anno 眼球運動">眼球運動</a>などの生理指標との関係については調べられてきたが<a href="#R1"><sup>1,2)</sup></a>，特定の夢の内容が脳において表現されているのかどうか，また，表現されているのであればどのように表現されているかに関しては，い<a href="#" class="anno まだ">まだ</a>に明らかにされていなかった．そこで，この研究では，<a href="#" class="anno 機能的MRI">機能的MRI</a>（MRI：mag<a href="#" class="anno net">net</a>ic resonance imaging，磁気共鳴画像）を用いて睡眠中の脳の活動を計測し，得られた脳活動の信号にパターン認識アルゴリズムを適用して解析することにより，脳の活動から夢の内容を解読できるかどうかを検証した．<br/><br/><h2>1．脳情報<a href="#" class="anno デ">デ</a>コーディング</h2><br/>　近年，<a href="#" class="anno 神経科学">神経科学</a>の分野において広く利用されるようになってきた“脳情報デコーディング”という手法は，被験者の脳の活動をパターン認識のアルゴリズムを用いて解析することにより，脳の活動に表現されている被験者の知覚の内容や運動の詳細な情報を予測（解読）する技術である<a href="#R3"><sup>3,4)</sup></a>．これまでの研究では，実際に画像を見ているときや課題を行っているときの脳の活動を対象としており，夢に代表されるような，外部からの刺激とは関係なく脳が自発的に生み出すイメージの解読は行われていなかった．しかし，われわれが見る夢の多くは<a href="#" class="anno 視覚的">視覚的</a>な体験をともなっており，画像を見たときと<a href="#" class="anno 同じ">同じ</a>ような視覚体験が生じている以上，夢を見ているときにも，画像を見ているときと同様の神経情報処理が脳において行われていることが予測される．そこでこの研究では，実際に画像を見ているとき計測した脳活動を用いて，見ている物体を脳活動パターンから予測するパターン認識アルゴリズム（デコーダー）を構築し，睡眠中のヒトの脳活動の信号を解析した．<br/><br/><h2>2．睡眠中の被験者からの脳の活動および夢の報告の収集</h2><br/>　夢を見ているときの脳の活動を解析する際の<a href="#" class="anno 問題点">問題点</a>として，大量の夢のデータを<a href="#" class="anno 効率的">効率的</a>に収集することがむずかしいという点があげられる．一般に，夢が頻繁に生じると考えられている<a href="#" class="anno レム睡眠">レム睡眠</a>（急速眼球運動，<a href="#" class="anno rap">rap</a>id <a href="#" class="anno eye">eye</a> movement：R<a href="#" class="anno EM">EM</a>をともなう睡眠）は，<a href="#" class="anno 入眠">入眠</a>からおよそ1時間半たたないと現われないため，この期間に見る夢を解析の対象とすることは<a href="#" class="anno データ収集">データ収集</a>の観点から考えると効率が悪い．一方で，多くの研究により，<a href="#" class="anno 入眠時">入眠時</a>にもレム睡眠中と類似した夢見体験の生じることが指摘されており，必ずしもレム睡眠中にのみ夢を見るわけではないという認識が広まりつつある<a href="#R5"><sup>5,6)</sup></a>．そこで，夢に関連する脳の活動と夢の報告データを効率的に収集するため，入眠時に見る夢に注目し，機能的MRIを用いて睡眠中の脳の活動の計測を行った（<a href="#F1">図1a</a>）．見る夢の内容をコントロールすることは一般に困難であるため，今回の研究では，被験者が見た夢の内容を言語により自由に報告させるという方法をとった．また，機能的MRIはスキャン音が大きく，装置の内部での睡眠はふだんの睡眠環境とは大きく異なるため，被験者を機能的MRIによる計測環境での睡眠に慣らし，また，実験の手続きに精通させるため，事前に実際の機能的MRIによる計測環境を模した<a href="#" class="anno 実験室">実験室</a>において順応のための睡眠実験を行った．実験の本番では，3人の被験者にMRI装置の内部で脳波電<a href="#" class="anno 極">極</a>を装着した状態で眠ってもらい，脳波をモニターして睡眠の状態をリアルタイムに判定しながら脳の活動の計測した．夢見と強い関連があると知られている睡眠の脳波パターンが生じたタイミングで被験者を起こし（睡眠の開始から約2～3分），直前まで見ていた夢の内容について自由に報告させた（約30秒）．得られた報告を記録し，再び被験者を眠りにつかせる，という手続きを何度もくり返すことにより，夢の報告とそれに対応する脳の活動のデータを大量に取得することができた（被験者あたり，約200回の夢の報告）．<br/><br/><a name="F1"></a><div id="fig1-caption-text" style="display: none;"><strong>図1　睡眠実験および夢報告データの概要</strong><br/>（a）睡眠実験の手続きの概要．吹き出しのなかの夢の報告は実験において実際に得られたものであり，赤色の文字の部分が解析の対象となった物体や風景を表す単語である．解析には，おもに覚醒直前の9秒間に得られた機能的MRIのデータを使用した．<br/>（b）夢の報告のベクトル表現．覚醒時（横軸）に得られた夢の報告に，主要な物体カテゴリー（縦軸）が含まれていたかどうかをそれぞれ白黒のセルで表した．おのおののカテゴリーに対応する画像をWebから収集し，それらの画像を見せているときの脳の活動をデコーダーの訓練に用いた．<br/><a href="http://first.lifesciencedb.jp/wp-content/uploads/2013/04/Kamitani-Science-13.4.26-Fig.1.jpg" target="_blank">[Download]</a></div>
                        <div id="figure1" class="hs-figure">
                            <div class="hs-figure-box">
                                <a class="highslide" title="図1　睡眠実験および夢報告データの概要" href="https://dbarchive.biosciencedbc.jp/data/first_authors/data/Fig/Kamitani-Science-13.4.26-Fig.1.jpg" target="_blank">
                                    <img src="https://dbarchive.biosciencedbc.jp/data/first_authors/data/Fig/Kamitani-Science-13.4.26-Fig.1.jpg" alt="figure1" width="200px" />
                                </a>
                            </div>
                            <div id="fig1-caption" class="hs-figure-caption"></div>
                        </div>

                        <script type="text/javascript">document.getElementById('fig1-caption').innerHTML = document.getElementById('fig1-caption-text').innerHTML;</script>
                        <div style='clear:both;'></div>
                        <br/><br/><br/><h2>3．言語データベースおよび画像データベースを用いた夢の報告の解析とデコーダーの構築</h2><br/>　被験者に夢の内容を自由に報告させたため，得られた夢の報告の内容は非常に多岐にわたっていた．このような<a href="#" class="anno 不定形">不定形</a>な夢報告データを<a href="#" class="anno 構造化">構造化</a>された<a href="#" class="anno かた">かた</a>ちに変換するため，夢の報告に頻繁に現われた主要な物体<a href="#" class="anno カ">カ</a>テゴリーを被験者ごとに特定し，おのおのの夢の報告を主要な物体カテゴリーの有無を表すベクトルにより表現しなおすという方略をとった．<a href="#" class="anno そのため">そのため</a>に，日本語で報告された被験者の夢の報告を記録したテキストデータから物体や風景を表す名詞を抽<a href="#" class="anno 出し">出し</a>，英単語へと翻訳した．そののち，英語の言語データベースWordNet <a href="#R7"><sup>7)</sup></a> を用いて同一のカテゴリーに属する単語群をまとめ，被験者ごとに夢に頻繁に現われる主要な物体カテゴリーを特定し（boyや<a href="#" class="anno man">man</a>などを<a href="#" class="anno mal">mal</a>eに，automobileやbusなどを<a href="#" class="anno car">car</a>にまとめるなど，被験者ごとに約20個のカテゴリー），おのおのの夢の報告をこれらのカテゴリーの有無を表すベクトルで表現した（<a href="#F1">図1b</a>）．この手続きにより，おのおのの夢の報告が得られた直前の睡眠中の脳の活動に対する解読の結果を，おのおのの主要な物体カテゴリーの有無を予測するというかたちで，<a href="#" class="anno 定量的">定量的</a>に評価することが可能になった．また，使用した言語データベースに関連づけられたWebの画像データベースを用いて主要な物体カテゴリーに対応する画像を収集し，それらの画像を見せたときの脳の活動を計測するという視覚画像提示実験を行った（<a href="#F1">図1b</a>）．この実験において計測された脳の活動を使い，見ている物体の情報を解読するデコーダーを構築した．このように，言語データベースおよび画像データベースを用いることにより，コントロールの困難で不定形な夢報告データを定量的に扱えるようにした点が，この研究における解読技術の特徴である．<br/><br/><h2>4．睡眠中の脳の活動からの視覚的な夢の内容の解読</h2><br/>　まず，実際に画像を見ているときの大脳の高次<a href="#" class="anno 視覚野">視覚野</a>における脳の活動を使い，物体カテゴリーのペアごと（male対carなど）に二値判別器を構築して，覚醒させる直前（0～9秒前）の脳の活動から，どちらの物体を見ていたかを判別できるどうか検証した．安定した評価が可能になるよう，十分な夢のデータサンプル数が確保できるペアについて解読の成績を調べた結果，3人の被験者から得られた全405ペアのうち，137ペアで<a href="#" class="anno 統計的">統計的</a>に有意な正当率が得られた．<br/>　つぎに，おのおののペアについて構築した二値判別器の出力を組み合わせることにより，おのおのの物体カテゴリーの有無を検出するデコーダーを構築した（<a href="#F2">図2a</a>）．このデコーダーは，睡眠中の脳活動データがあたえられると，おのおのの物体カテゴリーが存在する度合いを示す“スコア”を出力する．このデコーダーを用いて，覚醒直前の9秒間の脳活動データから夢の報告に現われた物体を正しく検出できるかどうか調べたところ，3人の被験者から得られた全60の主要物体カテゴリーのうち，18のカテゴリーについて有意な成績で検出することができた．また，デコーダーのスコアの<a href="#" class="anno 時間変化">時間変化</a>をみると，とくに覚醒の直前（0～15秒前）の脳活動データを用いた場合に，夢の報告に現われた物体カテゴリーに対するスコアが高い値を示した（<a href="#F2">図2b</a>）．これは，夢の報告の内容が覚醒直前の脳の活動を反映していることを意味している．また，報告に含まれる物体カテゴリーだけではなく，それと<a href="#" class="anno 関連性">関連性</a>の高いカテゴリーも高いスコアを示したことから（<a href="#F2">図2b</a>），報告はしなかったが実際には夢に現われていた物体がデコーダーの出力に反映されている<a href="#" class="anno 可能性">可能性</a>が考えられる．視覚野を細かく分割しそれぞれの部位において解読の精度を比較すると，<a href="#" class="anno 後頭葉">後頭葉</a>から<a href="#" class="anno 側頭">側頭</a>葉にかけて広がる高次視覚野を用いた場合により高い精度の得られることがわかった．高次視覚野はこれまでの研究から物体画像に対して強い活動を示すことが知られている<a href="#R8"><sup>8,9)</sup></a>．また，高次視覚野のなかでも，人の顔の画像に対し<a href="#" class="anno 選択的">選択的</a>に反応することが知られている<a href="#" class="anno 紡錘状回">紡錘状回</a>顔領域の活動を用いたときには人に関連するカテゴリー（male，femaleなど），風景の画像に対し選択的に反応することが知られている海馬傍回場所領域の活動を用いたときには風景に関するカテゴリー（s<a href="#" class="anno tre">tre</a>etやbuildingなど）に対し，高い成績が得られた．これらの結果から，夢を見ているときにも，実際に画像を見ているときと類似する脳活動パターンの生じていることが示唆された．<br/><br/><a name="F2"></a><div id="fig2-caption-text" style="display: none;"><strong>図2　脳の活動からの視覚的な夢の内容の解読</strong><br/>（a）解読の概要．画像を見せたときの脳の活動を用いて訓練したデコーダーにより，睡眠中の脳の活動から主要なカテゴリーの有無を予測した．<br/>（b）デコーダーが出力するスコアの時間変化．赤色の線は報告にあったカテゴリー，青色の線は報告にあったカテゴリーと関連の強いカテゴリーを示す．下部には，それぞれ覚醒の36秒前と6秒前のデコーダーの出力スコアに応じておのおのの物体カテゴリーの画像を重ね合わせたものと，スコアに応じて文字サイズを調整したタグクラウドを示した．画像は夢で見た物体の形や色を再構成したものではなく，その夢にどのような種類の物体や風景が現われていたかを表すものである（参照URL：<a href="http://www.youtube.com/watch?v=inaH_i_TjV4" target="_blank">http://www.youtube.com/watch?v=inaH_i_TjV4</a>）．<br/><a href="http://first.lifesciencedb.jp/wp-content/uploads/2013/04/Kamitani-Science-13.4.26-Fig.2.jpg" target="_blank">[Download]</a></div>
                        <div id="figure2" class="hs-figure">
                            <div class="hs-figure-box">
                                <a class="highslide" title="図2　脳の活動からの視覚的な夢の内容の解読" href="https://dbarchive.biosciencedbc.jp/data/first_authors/data/Fig/Kamitani-Science-13.4.26-Fig.2.jpg" target="_blank">
                                    <img src="https://dbarchive.biosciencedbc.jp/data/first_authors/data/Fig/Kamitani-Science-13.4.26-Fig.2.jpg" alt="figure2" width="200px" />
                                </a>
                            </div>
                            <div id="fig2-caption" class="hs-figure-caption"></div>
                        </div>

                        <script type="text/javascript">document.getElementById('fig2-caption').innerHTML = document.getElementById('fig2-caption-text').innerHTML;</script>
                        <div style='clear:both;'></div>
                        <br/><br/><br/><h2>おわりに</h2><br/>　これらの結果は，夢の内容が睡眠中の脳活動パターンを反映していることをはじめて<a href="#" class="anno 実験的">実験的</a>に証明したものである．今回の研究では，データ収集の効率を高めるためレム睡眠中に見る夢ではなく<a href="#" class="anno 入眠期">入眠期</a>に見る夢に焦点をあてて解析を行ったが，レム睡眠中に見る夢と入眠期に見る夢は類似していることや<a href="#R5"><sup>5)</sup></a>，レム睡眠中にも視覚野での活動が観察されることを考えると<a href="#R10"><sup>10)</sup></a>，この手法がレム睡眠中の夢を解読することにも有効なことは大いに期待できる．ただし，その<a href="#" class="anno 有効性">有効性</a>について明らかにするためには，レム睡眠中に得られた脳活動データを用いた同様の解析による検証が必要である．この研究で使用したデコーダーは，睡眠実験で得られた夢の報告をもとに決定した物体カテゴリーについて構築したものであり，解読の対象とする物体カテゴリーをあらかじめ決めてから構築したものではない．しかし，今回，解析の対象とした60の主要な物体カテゴリーのうち59のカテゴリーが数日間にわたる睡眠実験の前半と後半のいずれにおいて報告されており，<a href="#" class="anno 一般性">一般性</a>の高いカテゴリーであるといえる．したがって，今回，構築したデコーダーは，今後，新たに得られる睡眠データに対しても有効であると考えられる．<br/>　夢はときに現実と区別がつかないほど鮮やかで多様な感覚をひき起こす体験である．今回の研究から，睡眠中の高次視覚野の脳の活動から夢に現われる物体や風景の情報を高い精度で解読できることがわかった．一方で，夢のなかに現われた色や形などほかの視覚特徴を解読できるかどうかはまだ明らかでない．また，夢のなかでの体の動きや感情など，視覚以外の要素が脳の別の領野において表現されているかどうかも明らかにされていない．筆者らは，今後，このアプローチを応用し発展させていくことにより，より多様な夢の内容の解読が可能かどうか検証していく予定である．脳から解読される夢の内容と覚醒時の経験や行動とを比較することにより，われわれの経験や行動をかたちづくるうえで，夢がどのような機能をはたしているかについて手がかりが得られるかもしれない．<br/>　この研究から，刺激や課題によりひき起こされる脳の活動だけでなく，自発的に生じる脳の活動からでも，脳活動パターンに表現されている情報を解読することが可能であることが示された．したがって，この研究で用いた方法は，夢だけではなく，想像や幻覚などの内容を解読するためにも用いることができると考えられ，今後，ブレインマシンインターフェース，心理状態の<a href="#" class="anno 可視化">可視化</a>，精神疾患の診断など，広い分野での応用が期待される．<br/><br/><h2>文 献</h2><br><ol><br><li id="R1"><span class='au'>Dement, W. & Kleitman, N.</span>: <span class="ti">The relation of eye movements during sleep to dream activity: an objective method for the study of dreaming.</span> <span class='so'>J. Exp. Psychol., 53, 339-346 (1957)[<a href="http://www.ncbi.nlm.nih.gov/pubmed/13428941" target="_blank">PubMed</a>]</span></li><br><li id="R2"><span class='au'>Marzano, C., Ferrara, M., Mauro, F. et al.</span>: <span class="ti">Recalling and forgetting dreams: theta and alpha oscillations during sleep predict subsequent dream recall.</span> <span class='so'>J. Neurosci., 31, 6674-6683 (2011)[<a href="http://www.ncbi.nlm.nih.gov/pubmed/21543596" target="_blank">PubMed</a>]</span></li><br><li id="R3"><span class='au'>Kamitani, Y. & Tong, F.</span>: <span class="ti">Decoding the visual and subjective contents of the human brain.</span> <span class='so'>Nat. Neurosci., 8, 679-685 (2005)[<a href="http://www.ncbi.nlm.nih.gov/pubmed/15852014" target="_blank">PubMed</a>]</span></li><br><li id="R4"><span class='au'>Miyawaki, Y., Uchida, H., Yamashita, O. et al.</span>: <span class="ti">Visual image reconstruction from human brain activity using a combination of multiscale local image decoders.</span> <span class='so'>Neuron, 60, 915-929 (2008)[<a href="http://www.ncbi.nlm.nih.gov/pubmed/19081384" target="_blank">PubMed</a>]</span></li><br><li id="R5"><span class='au'>Oudiette, D., Dealberto, M. J., Uguccioni, G. et al.</span>: <span class="ti">Dreaming without REM sleep.</span> <span class='so'>Conscious. Cogn., 21, 1129-1140 (2012)[<a href="http://www.ncbi.nlm.nih.gov/pubmed/22647346" target="_blank">PubMed</a>]</span></li><br><li id="R6"><span class='au'>Nir, Y. & Tononi, G.</span>: <span class="ti">Dreaming and the brain: from phenomenology to neurophysiology.</span> <span class='so'>Trends Cogn. Sci., 14, 88-100 (2010)[<a href="http://www.ncbi.nlm.nih.gov/pubmed/20079677" target="_blank">PubMed</a>]</span></li><br><li id="R7"><span class='au'>Fellbaum, C. (ed.)</span>: <span class="ti">WordNet: An Electronic Lexical Database.</span> <span class='so'>MIT Press, Cambridge (1998)</span></li><br><li id="R8"><span class='au'>Epstein, R. & Kanwisher, N.</span>: <span class="ti">A cortical representation of the local visual environment.</span> <span class='so'>Nature, 392, 598-601 (1998)[<a href="http://www.ncbi.nlm.nih.gov/pubmed/9560155" target="_blank">PubMed</a>]</span></li><br><li id="R9"><span class='au'>Kanwisher, N., McDermott, J., Chun, M. M.</span>: <span class="ti">The fusiform face area: a module in human extrastriate cortex specialized for face perception.</span> <span class='so'>J. Neurosci., 17, 4302-4311 (1997)[<a href="http://www.ncbi.nlm.nih.gov/pubmed/9151747" target="_blank">PubMed</a>]</span></li><br><li id="R10"><span class='au'>Miyauchi, S., Misaki, M., Kan, S. et al.</span>: <span class="ti">Human brain activity time-locked to rapid eye movements during REM sleep.</span> <span class='so'>Exp. Brain Res., 192, 657-667 (2009)[<a href="http://www.ncbi.nlm.nih.gov/pubmed/18830586" target="_blank">PubMed</a>]</span></li><br></ol><br><br><h2>生命科学の教科書における関連するセクションへのリンク</h2><br><a href="http://www.adves.c.u-tokyo.ac.jp/" target="_blank">東京大学 大学院総合文化研究科・教養学部附属教養教育高度化機構自然科学教育高度化部門</a>から公開されている生命科学の教科書 “<a href="http://csls-text3.c.u-tokyo.ac.jp/" target="_blank">A Comprehensive Approach To LIFE SCIENCE</a>”（羊土社『理系総合のための生命科学 第2版』の英語版）における関連するセクションへのリンクです．<br><ul><br><li><a href="http://csls-text3.c.u-tokyo.ac.jp/inactive/01_07.html" target="_blank">1.7 Major Classification of Organisms</a></li><br><li><a href="http://csls-text3.c.u-tokyo.ac.jp/inactive/12_05.html" target="_blank">12.5 Exocytosis</a></li><br><li><a href="http://csls-text3.c.u-tokyo.ac.jp/inactive/11_02.html" target="_blank">11.2 Characteristic Structures in Prokaryotes</a></li><br><li><a href="http://csls-text3.c.u-tokyo.ac.jp/inactive/22_08.html" target="_blank">22.8 Formation of Floral Organs</a></li><br><li><a href="http://csls-text3.c.u-tokyo.ac.jp/inactive/01_05.html" target="_blank">1.5 Unicellular and Multicellular Organisms</a></li><br></ul><br><br><div class="au-profile"><br><h2>著者プロフィール</h2><br><span class="author">堀川 友慈（Tomoyasu Horikawa）</span><br>略歴：2013年 奈良先端科学技術大学院大学情報科学研究科 単位取得退学，同年より国際電気通信基礎技術研究所（ATR）研究員．<br>研究テーマ：脳情報デコーディング技術の開発．<br>関心事：ヒトの視覚的な意識における神経基盤の解明と，脳活動を利用した新しい技術の開発．<br><br><strong>神谷 之康（Yukiyasu Kamitani）</strong><br>国際電気通信基礎技術研究所（ATR）室長．<br>研究室URL：<a href="http://www.cns.atr.jp/dni/" target="_blank">http://www.cns.atr.jp/dni/</a><br></div><br>© 2013 堀川友慈・神谷之康 Licensed under <a href="http://creativecommons.org/licenses/by/2.1/jp/" target="_blank">CC 表示 2.1 日本</a>
                </div>

            </div>
        </div>

        <!-- begin r_sidebar -->

        <div id="r_sidebar">
            <ul class="l_sidebarwidgeted">

                <li id="search-6" class="widget widget_search">
                    <!--
                    <form role="search" method="get" id="searchform" class="searchform"
                          action="http://first.lifesciencedb.jp/">
                        <div>
                            <label class="screen-reader-text" for="s">検索:</label>
                            <input type="text" value="" name="s" id="s">
                            <input type="submit" id="searchsubmit" value="検索">
                        </div>
                    </form>
                    -->
                </li>


                <li class="widget widget_text"><h2 class="widgettitle">このサイトについて</h2>
                    <div class="textwidget">
                        <a href="http://dbcls.rois.ac.jp/" class="img_item">
                            <img alt="DBCLS" style="border-width:0"
                                 height="71" width="158"
                                 src="images/logo_en_c.png"
                                 class="logo">
                        </a>
                        <p class="about_text">
                            トップジャーナルに掲載された日本人を著者とする生命科学分野の論文について，
                            論文の著者自身の執筆による日本語のレビューを，だれでも自由に閲覧・利用できるよう，いち早く公開します．
                            くわしくは、 「新着論文レビュー」とは をご覧ください．
                        </p>
                        <a href="http://togotv.dbcls.jp/20110301.html#p01" class="img_item">
                            <img src="http://first.lifesciencedb.jp/wp-content/uploads/2011/03/togotv20110301_small-1.png">
                        </a><br>
                        <a href="http://togotv.dbcls.jp/">統合TV</a>にて
                        <a href="http://togotv.dbcls.jp/20110301.html#p01">解説動画</a>を公開しました

                    </div>
                </li>


            </ul>

        </div>

        <!-- end r_sidebar -->

    </div>

    <!-- The main column ends  -->

</div>
<!-- end wrap -->
<div style="clear:both;"></div>
<div style="clear:both;"></div>

<!-- begin footer -->
<div class="bottom_indexes"></div>


<div id="footer">
    <ul id="footer-navi">
        <li><a href="/">ページトップにもどる</a></li>
        <li><a href="http://dbcls.rois.ac.jp/">DBCLS</a></li>
        <li><a href="http://lifesciencedb.jp/">LSDB</a></li>
        <li><a href="http://lifesciencedb.jp/lsdb.cgi?lng=jp&amp;gg=policy">サイトポリシー</a></li>
        <li><a href="http://lifesciencedb.jp/lsdb.cgi?lng=jp&amp;gg=support">お問い合わせ</a></li>
    </ul>
</div>


<!-- .modal-profile -->
<div class="modal fade modal-profile" tabindex="-1" role="dialog" aria-labelledby="modalProfile" aria-hidden="true">
    <div class="modal-dialog modal-lg">
        <div class="modal-content">
            <div class="modal-header">
                <button class="close" type="button" data-dismiss="modal">×</button>
                <span class="modal-title"></span>
            </div>
            <div class="modal-body">
            </div>
            <div class="modal-footer">
                <button class="btn btn-default" data-dismiss="modal">Close</button>
            </div>
        </div>

    </div>
</div>
<!-- //.modal-profile -->

<!-- Hovercardに表示するDB選択 -->
<div style="display: none;">
    <form>
        <input type="checkbox" class="selected_db" name="targetdb" value="dbpedia" checked>DBpedia
        <input type="checkbox" class="selected_db" name="fa" value="fa" checked>FirstAuthor検索
    </form>
</div>

<script type="text/javascript" src="./js/jquery.hovercard.js"></script>
<script type="text/javascript" src="./js/config.js"></script>
<script src="https://cdn.jsdelivr.net/npm/riot@3.7/riot+compiler.min.js"></script>
<script type="riot/tag" src="js/drawer-category.tag"></script>
<script type="riot/tag" src="js/drawer-journal.tag"></script>
<script type="riot/tag" src="js/drawer-date.tag"></script>


<script type="text/javascript">
    Array.prototype.uni = function () {
        return [...new Set(this)]
    };

    function selected_db() {
        var dbs = [];
        $('.selected_db:checked').each(function () {
            dbs.push($(this).val());
        });
        dbs = dbs.uni();
        var selected = cards.filter(function (e, i, a) {
            return dbs.includes(e.dbname)
        });
        return selected
    }

    $(document).ready(function () {
        $('#search_val').keypress(function (e) {
            if (e.keyCode == 13) {
                e.preventDefault()
                var url = "./search.htm?val=" + $("#search_val").val();
                location.href = url
            }
        });
        $("#searchsubmit").click(function () {
            var url = "./search.htm?val=" + $("#search_val").val();
            location.href = url
        });

        $('.drawer').drawer();
        $('.drawer').on('drawer.opened', function () {
            $('body,html').css({"overflow": "hidden", "height": "100%"});
        });
        $('.drawer').on('drawer.closed', function () {
            $('body,html').css({"overflow": "visible", "height": "auto"});
        });

        var cardBase = '<div class="hc-refers"></div>';

        $(".anno").hovercard({
            detailsHTML: cardBase,
            showCustomCard: false,
            width: 400,
            onHoverIn: function () {
                var kw = this.firstChild.textContent;
                var rows = 0;
                selected_db().forEach(function (v, i, a) {
                    $(".hc-refers").empty();
                    $.ajax({
                        type: v.ajax_conf.type,
                        url: v.get_url(kw),
                        dataType: v.ajax_conf.dataType
                    }).then(function (d) {
                        var req_type = v["request_type"];
                        var pages = parser[req_type](d);

                        if (pages.length > 0) {
                            rows += pages.length;
                            var t = v.title(kw)
                            $(".hc-refers").append(t);

                            var i = 0;
                            while (i < pages.length && i < v.max_lines) {
                                var c = pages[i];
                                var elem = v.views(kw, c);
                                $(".hc-refers").append(elem);
                                i++
                            }
                        }
                    });
                });
                if (rows > 0) {
                    $(".hc-details .s-card").attr("style", "display:block");
                } else {
                    $(".hc-details .s-card").attr("style", "display:none");
                }
            }
        });

        riot.compile(function () {
            tags = riot.mount("*");
        });


        // ligthbox modal
        $('a.highslide').click(function (event) {　// a.thumb内のhtmlをmodal-bodyに挿入
            event.preventDefault();
            var content = $('.modal-body'); //.modal-body初期化
            content.empty();
            var title = $(this).attr("title");
            $('.modal-title').html(title); // h3を定義
            content.html($(this).html());　//.modal-bodyにthisを挿入
            $('.modal-body img').width("50%"); //modalのimageのサイズを変更
            $(".modal-profile").modal({show: true});　//modalを表示
        });


    });


</script>

<script type="text/javascript"
        src="https://dbcls.rois.ac.jp/DBCLS-common-header-footer/common-header-and-footer/script/common-header-and-footer.js"
        style="display: block" id="common-header-and-footer__script" data-page-type="2.1"></script>

</body>
</html>